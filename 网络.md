# UDP介绍









# 其他

  ### IP

  - 网络层协议

  ### TCP

  - 参考于[面试官，不要再问我三次握手和四次挥手](https://blog.csdn.net/hyg0811/article/details/102366854)


  #### 首部格式

  - 参考[TCP报文段的首部格式](https://blog.csdn.net/qq_32998153/article/details/79680704)

  - 源端口号（2字节）
  - 目的端口号（2字节）
  - 包序列号（4字节）
  - 确认序号（4字节）
  - 数据偏移（4位），即TCP报文段的数据起始处距离TCP报文段的起始处有多远。
  - 保留（6位）
  - 控制位（6个，各占1位）
    - 紧急URG
    - 确认ACK
    - 推送PSH
    - 复位RST
    - 同步SYN
    - 终止FIN
  - 窗口（2字节）
  - 检验和（2字节）
  - 紧急指针（2字节）

  #### 三次握手

  - 第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN。此时客户端处于 `SYN_SENT` 状态。

    首部的同步位SYN=1，初始序号seq=x，SYN=1的报文段**不能携带数据（？三次握手的时候可不可以携带数据）**，但要消耗掉一个序号。

  - 第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)。同时会把客户端的 ISN + 1 作为ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 `SYN_RCVD` 的状态。

    在确认报文段中SYN=1，ACK=1，确认号ack=x+1，初始序号seq=y。进入半连接状态。

  - 第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 `ESTABLISHED` 状态。服务器收到 ACK 报文之后，也处于 `ESTABLISHED` 状态，此时，双方已建立起了连接。

    确认报文段ACK=1，确认号ack=y+1，序号seq=x+1（初始为seq=x，第二个报文段所以要+1），**ACK报文段可以携带数据**，不携带数据则不消耗序号。

  #### 为什么需要三次握手，两次不行吗？

  - 参考于[TCP 为什么三次握手而不是两次握手（正解版）](https://blog.csdn.net/lengxiao1993/article/details/82771768?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control)

  - 第一次握手：客户端发送网络包，服务端收到了。
    这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。
  - 第二次握手：服务端发包，客户端收到了。
    这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。
  - 第三次握手：客户端发包，服务端收到了。
    这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。
  - 为了实现可靠数据传输， TCP 协议的通信双方， 都必须维护一个序列号， 以标识发送出去的数据包中， 哪些是已经被对方收到的。 三次握手的过程即是通信双方相互告知序列号起始值， 并确认对方已经收到了序列号起始值的必经步骤。如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认

  #### 四次挥手

  - 四次挥手由TCP的半关闭（half-close）造成的。所谓的半关闭，其实就是TCP提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力。
  - 第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于 `FIN_WAIT1` 状态。
    即发出**连接释放报文段**（FIN=1，序号seq=u），并停止再发送数据，主动关闭TCP连接，进入FIN_WAIT1（终止等待1）状态，等待服务端的确认。
  - 第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 +1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 `CLOSE_WAIT` 状态。
    即服务端收到连接释放报文段后即发出**确认报文段**（ACK=1，确认号ack=u+1，序号seq=v），服务端进入CLOSE_WAIT（关闭等待）状态，此时的TCP处于半关闭状态，客户端到服务端的连接释放。客户端收到服务端的确认后，进入FIN_WAIT2（终止等待2）状态，等待服务端发出的连接释放报文段。
  - 第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 `LAST_ACK` 的状态。
    即服务端没有要向客户端发出的数据，服务端发出**连接释放报文段**（FIN=1，ACK=1，序号seq=w，确认号ack=u+1），服务端进入LAST_ACK（最后确认）状态，等待客户端的确认。
  - 第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 +1 作为自己 ACK 报文的序列号值，此时客户端处于 `TIME_WAIT` 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态，服务端收到 ACK 报文之后，就处于关闭连接了，处于 `CLOSED` 状态。
    即客户端收到服务端的连接释放报文段后，对此发出**确认报文段**（ACK=1，seq=u+1，ack=w+1），客户端进入TIME_WAIT（时间等待）状态。此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL后，客户端才进入CLOSED状态。

  #### 如何处理三次握手中最后一次丢包？

  - 服务器收到SYN包后发出SYN+ACK数据包，服务器进入SYN_RECV状态。而这个时候客户端发送ACK给服务器失败了，服务器没办法进入ESTABLISH状态，这个时候肯定不能传输数据的，不论客户端主动发送数据与否，服务器都会有定时器发送第二步SYN+ACK数据包，如果客户端再次发送ACK成功，建立连接。
  - 如果一直不成功，服务器肯定会有超时（大概64s）设置，超时之后会给客户端发RTS报文，进入CLOSED状态，防止SYN泛洪攻击，这个时候客户端应该也会关闭连接。

  #### TCP是如何实现可靠传输的？

  - 参考[TCP/IP是如何实现可靠传输的](https://blog.csdn.net/shawjan/article/details/45117945)

  ##### 介绍

  - TCP/IP可靠传输的基础是滑动窗口协议和连续ARQ协议，配合着流量控制和拥塞控制，使得整个传输过程保证 
    - 传输信道不产生差错
    - 不管发送方以多快的速度发送数据，接收方总是来得及处理收到的数据（通过累计确认、超时重传、拥塞控制三大模块保证）

  ##### 停止等待协议介绍和自动重传请求（ARQ）

  - 所谓停止等待协议就是每发送完一个分组就停止发送，等待对方的确认。在收到确认后再发送下一个分组。但是在传输过程中可能出现意外，这时候就需要用到ARQ协议了。
  - B可能没有收到A发送的M1
    - 这时候A就会有个超时计时器，当超时计时器到期时没收到B的确认报文，则A重新发送M1M1，因此必须保证以下几点：
      - A发送完一个分组后，必须暂时保留已发送的分组副本，只有在收到确认后才能消除分组副本。
      - 分组和确认分组都必须进行编号。
      - 超时计时器设置的重传时间应当比数据在分组传输的往返时间更长一些。
  - B收到了A发送的分组，但是A没有收到B的确认报文或报文迟到
    - 发生确认丢失时，B会再一次收到A的重传分组，此时B会丢弃这个重复分组并向A发送确认报文。
    - 发生确认迟到时，A会再一次收到B的确认报文，这时候A收下并丢弃这个确认报文，并不做什么。

  ##### 滑动窗口协议和连续ARQ协议

  - 发送方和接收方各自维持着发送窗口和接受窗口，发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置。接收方一般采用累计确认方式，即接收方不必对收到的分组逐个发送确认，而是可以在收到几个分组后，对按序到达的最后一个分组发送确认，这样就表示：到这个分组位置的所有分组都已经正确收到了。
  - 滑动窗口分四个部分，分别为：已发送确认并交付主机、已发送但未收到确认、允许但尚未发送、不允许发送

  - 当允许发送但尚未发送减小到0的时候，必须停止发送。此时A设置了超时计时器，超时计时器到期时就重传这部分数据，重置超时计时器，直到收到B的确认为止。
  - 发送缓存与发送窗口、接收缓存与接收窗口
    - 发送缓存用来暂时存放(即发送窗口)：
      - 发送应用程序传送给发送方TCP准备发送的数据
      - TCP已经发送出但尚未收到确认的数据
    - 接收缓存用来暂时存放：
      - 按序到达的、但尚未被接收应用程序读取的数据
      - 未按序到达的数据
  - 发送缓存和接收缓存小结
    - A的发送窗口根据B的接收窗口设置，但是二者并以总是一样大
    - 对于不按序到达的数据应如何处理，TCP彼岸准并无明确规定(一般都是临时保存在接收窗口中，等到字节流完整接收后再按序提交给上层的应用进程)
    - TCP要求接收方必须有累积确认的功能，这样子可以减少传输开销
  - 超时重传时间（RTO）的确定
    - TCP的发送方在规定的时间内没有收到确认就要重传已发送的报文段。但是由于TCP的下层互联网环境，发送的报文段可能只经过一个高速率的局域网，也可能经过多个低速率的网络，并且每个IP数据报所选择的路由还可能不同，因此注定超时重传时间要动态变化。
    - 略大于加权平均往返时间

  ##### 后退N帧协议

  - 当接收方检测出失序的信息帧后，要求发送方重发最后一个正确接收的信息帧之后的所有未被确认的帧；或者当发送方发送了N个帧后，若发现该N帧的前一个帧在计时器超时后仍未返回其确认信息，则该帧被判为出错或丢失，此时发送方就不得不重新发送出错帧及其后的N帧。这就是GO-DACK-N(退回N)法名称的由来。因为，对接收方来说，由于这一帧出错， 就不能以正常的序号向它的高层递交数据，对其后发送来的N帧也可能都不能接收而丢弃。

  ##### 流量控制

  - 双方在通信的时候，发送方的速率与接收方的速率是不一定相等，如果发送方的发送速率太快，会导致接收方处理不过来，这时候接收方只能把处理不过来的数据存在缓存区里（失序的数据包也会被存放在缓存区里）。如果缓存区满了发送方还在疯狂着发送数据，接收方只能把收到的数据包丢掉，大量的丢包会极大着浪费网络资源，因此，我们需要控制发送方的发送速率，让接收方与发送方处于一种动态平衡才好。对发送方发送速率的控制，我们称之为流量控制。
  - 如何控制：接收方每次收到数据包，可以在发送确定报文的时候，同时告诉发送方自己的缓存区还剩余多少是空闲的，我们也把缓存区的剩余大小称之为接收窗口大小（rwnd）。发送缓存不一定比接受缓存大。
  - 持续计时器：假如B向A发送了零窗口的报文段后不久，B的接收缓存又有了一些存储控件。于是B向A发送了rwnd = 400的报文段。然而这个报文段在发送过程中丢失了。酱紫A就一直等待B发送的非零窗口的通知，B也一直等待A发送数据，导致死锁。因此需要一个持续计时器，当TCP链接的一方收到对方的零窗口通知，就启动持续计时器。持续计时器时间到时就发送一个零窗口探测报文段，而对方就在确认这个探测报文段时给出了现在的窗口值。如果窗口仍为零，那么持续计时器就重新计时。如果不为零，则可以打破死锁。

  ##### 拥塞控制

  - 参考[TCP的拥塞控制（详解）](https://blog.csdn.net/qq_41431406/article/details/97926927)
  - 参考[TCP的快速重传机制](https://blog.csdn.net/whgtheone/article/details/80983882)

  - 介绍：
    - 若网络中有许多资源同时出现供应不足，网络性能就要明显变化，整个网络的吞吐量将随着输入负荷的增大而下降，这就是拥塞。
    - 拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不至于过载。
    - 流量控制往往指点对点的通信量的控制，是一个端到端端额问题。拥塞控制则是当整个挽留过的输入负载超过网络所能承受的时候，向发送方发送控制报文，并告诉发送端，必须放慢发送速率。
  - 慢开始和拥塞避免：
    - 发送方维持一个拥塞窗口(cwnd)的状态变量。其大小取决于网络的拥塞程度，并且动态的在变化。发送方让自己的发送窗口小于或等于拥塞窗口。
    - 慢开始的算法思路是：
      - 发送窗口先设置cwnd = 1，发送第一个报文段，以后每收到一个报文段确认，cwnd就变为原来的2倍（即呈指数增长）
      - 当cwnd大于ssthresh（慢启动阀值）时，改用**拥塞避免**算法(每次+1)
      - 假设增长到某值，网络出现超时，此时将ssthresh值变为值的一半(乘法减小)，然后将cwnd置1，重新采用慢开始算法，重复如上步骤。

  - 快重传和快恢复

    - 快重传

      - 要求接收方每收到一个时序的报文段后就立即发出重复确认，而不是等待发送数据时才进行捎带确认
      - 发送方只要一连收到三个重复确认，就应当立即重传对方尚未收到的报文段，而不必等待设置的重传计时器到期

    - 快重传为什么是三次冗余axk？

      - 参考[TCP快速重传为什么是三次冗余ack，这个三次是怎么定下来的？](https://blog.csdn.net/u010202588/article/details/54563648)

      - 两次duplicated ACK时很可能是乱序造成的！三次duplicated ACK时很可能是丢包造成的！四次duplicated ACK更更更可能是丢包造成的！但是这样的响应策略太慢。丢包肯定会造成三次duplicated ACK!综上是选择收到三个重复确认时窗口减半效果最好，这是实践经验。

    - 快恢复

      - 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把慢开始阀值ssthresh减半
      - 接着不执行慢开始，而是从新阀值ssthresh开始执行拥塞避免算法(加法增大)

  - 三个窗口

    - 接收窗口rwnd（receive window）
    - 发送窗口swnd（send window）
    - 拥塞窗口cwnd （congestion window）

  #### SYN泛洪攻击

  - SYN攻击利用的是TCP的三次握手机制，攻击端利用伪造的IP地址向被攻击端发出请求，而被攻击端发出的响应报文将永远发送不到目的地，那么被攻击端在等待关闭这个连接的过程中消耗了资源，如果有成千上万的这种连接，主机资源将被耗尽，从而达到攻击的目的。

  - TCP SYN泛洪发生在OSI第四层，这种方式利用TCP协议的特性，就是三次握手。攻击者发送TCP SYN，SYN是TCP三次握手中的第一个数据包，而当服务器返回ACK后，该攻击者就不对其进行再确认，那这个TCP连接就处于挂起状态，也就是所谓的半连接状态，服务器收不到再确认的话，还会重复发送ACK给攻击者。这样更加会浪费服务器的资源。攻击者就对服务器发送非常大量的这种TCP连接，由于每一个都没法完成三次握手，所以在服务器上，这些TCP连接会因为挂起状态而消耗CPU和内存，最后服务器可能死机，就无法为正常用户提供服务了。

  - 解决方法：

    - 参考[TCP SYN洪泛攻击的原理及防御方法](https://blog.csdn.net/shixin_0125/article/details/78829069)

    - 增加TCP backlog队列

    - 减少SYN-RECEIVED的时间
    - SYN缓存
    - SYN Cookies

  #### 半连接和全连接

  -  Linux内核协议栈为一个tcp连接管理使用两个队列，一个是半连接队列（用来保存处于SYN_SENT和SYN_RECV状态的请求），一个是全连接队列（accpetd队列）（用来保存处于established状态，但是应用层没有调用accept取走的请求）。
  -  全连接队列的大小取决于：min(tcp_max_syn_backlog, net.core.somaxconn)
  -  半连接队列的大小取决于：max(64, tcp_max_syn_backlog)

  ### UDP

  - 参考[UDP协议的详细解析](https://blog.csdn.net/aa1928992772/article/details/85240358)

  #### 首部格式

  - UDP首部有8个字节，由4个字段构成，每个字段都是两个字节
  - 源端口： 源端口号，需要对方回信时选用，不需要时全部置0.
  - 目的端口：目的端口号，在终点交付报文的时候需要用到。
  - 长度：UDP的数据报的长度（包括首部和数据）其最小值为8（只有首部）
  - 校验和：检测UDP数据报在传输中是否有错，有错则丢弃。该字段是可选的，当源主机不想计算校验和，则直接令该字段全为0.
  - 当传输层从IP层收到UDP数据报时，就根据首部中的目的端口，把UDP数据报通过相应的端口，上交给应用进程。如果接收方UDP发现收到的报文中的目的端口号不正确（不存在对应端口号的应用进程0,），就丢弃该报文，并由ICMP发送“端口不可达”差错报文给对方。

  ### TCP和UDP的区别

  - 参考[一文搞懂TCP与UDP的区别](https://www.cnblogs.com/fundebug/p/differences-of-tcp-and-udp.html)
  - 参考[UDP协议的详细解析](https://blog.csdn.net/aa1928992772/article/details/85240358)
  - 参考[TCP 和 UDP 的区别](https://blog.csdn.net/zhang6223284/article/details/81414149?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control)
  - 对比：

    - 是否面向连接：UDP：无连接；TCP：面向连接。

    - 是否可靠：

      - UDP：不可靠传输，不使用流量控制和拥塞控制；只有通过检验和去丢弃那些不完整的报文，尽最大努力来保证交付的可靠性。

      - TCP：可靠传输，需要三次握手来建立连接，并且通过数据校验、拥塞控制、重传控制、滑动窗口和确认应答等机制来实现可靠交付。

    - 工作效率：

      - TCP：传输数据的控制非常多，导致网络开销大，工作效率相对低下，对系统的资源要求也比较高。
      - UDP：传输控制简单，因此工作效率相对高，对系统资源的要求偏低。

    - 连接对象个数：UDP：支持一对一，一对多，多对一和多对多交互通信；TCP：只能是一对一通信。

    - 传输方式：

      - UDP：面向报文。对应用层交下来的报文，添加首部后直接向下交付为IP层，既不合并，也不拆分，保留这些报文的边界。对IP层交上来UDP用户数据报，在去除首部后就原封不动地交付给上层应用进程，报文不可分割，是UDP数据报处理的最小单位。正是因为这样，UDP显得不够灵活，不能控制读写数据的次数和数量。比如我们要发送100个字节的报文，我们调用一次sendto函数就会发送100字节，对端也需要用recvfrom函数一次性接收100字节，不能使用循环每次获取10个字节，获取十次这样的做法。
      - TCP： 面向字节流。

    - 首部开销：UDP：首部开销小，仅8字节；TCP： 首部最小20字节，最大60字节。

    - 安全性：

      - TCP：TCP传输机制多，容易被利用，例如DOS、DDOS攻击，因此在安全性上，不如UDP。
      - UDP：UDP没有TCP这么多机制，被利用的机会就会少很多，但UDP不是绝对安全，也会被攻击。

    - 实时性：

      - TCP传输数据的控制程序较多，大幅度降低了数据传输的实时性。
      - UDP协议简单，数据实时性较高。

    - 适用场景：

      - UDP：只对数据传输的实时性要求较高，但不对传输质量有要求。比如视频传输、IP电话、视频会议、直播、实时通信等适用于实时的应用。
      - TCP：对数据传输的质量有较高要求，但对实时性要求不高。比如HTTP，HTTPS，FTP等传输文件的协议以及POP，SMTP等邮件传输的协议。
  - 总结：

    - TCP向上层提供面向连接的可靠服务 ，UDP向上层提供无连接不可靠服务。
    - 虽然 UDP 并没有 TCP 传输来的准确，但是也能在很多实时性要求高的地方有所作为
    - 对数据准确性要求高，速度可以相对较慢的，可以选用TCP

  ### HTTP

  #### 介绍

  - HTTP即超文本传输协议（Hyper Text Transfer Protocol）
  - 基于TCP/IP通信协议来传递数据。

  - 工作原理
    - HTTP协议工作于客户端-服务端架构上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。
    - HTTP默认端口号为80，但是也可以改为8080或者其他端口。
    - 注意事项：
      - HTTP是无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。
      - HTTP是媒体独立的：这意味着，只要客户端和服务器知道如何处理的数据内容，任何类型的数据都可以通过HTTP发送。客户端以及服务器指定使用适合的MIME-type内容类型。
      - HTTP是无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快

  #### 消息结构

  - 参考[HTTP报文的结构](https://blog.csdn.net/kongmin_123/article/details/82154780)

  - 客户端请求消息（请求报文）

    - 报文首部->请求行

      - 请求方法、空格、URL、空格、协议版本、回车符、换行符

    - 报文首部->请求头部

      - 头部字段名、值、回车符、换行符
      - ...
      - 头部字段名、值、回车符、换行符

    - 空行

      - 回车符、换行符

    - 报文主体->请求数据

    - ```
      GET / HTTP/1.1
      Host: www.enjoytoday.cn
      Connection: keep-alive
      Upgrade-Insecure-Requests: 1
      User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.84 Safari/537.36
      Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
      Referer: http://www.enjoytoday.cn/posts/326
      Accept-Encoding: gzip, deflate, sdch
      Accept-Language: zh-CN,zh;q=0.8
      Cookie: bdshare_firstime=1466032270994; UM_distinctid=15c4ef2ac4e2e4-0d13269271b947-1b2a120b-1fa400-15c4ef2ac4f7b5; un=aGZjYWk=; comment_author=aGZjYWk=; comment_author_email=1710600212@qq.com; comment_author_url=http://www.enjoytoday.cn; c_id=dUhIaTlndmc4MVVYbjRQTGxMRTotMTpFODg3QjgzQjg1NjgxQjQxRUYxNjg2QzJFRkMyQjI2QQ==; JSESSIONID=ADBC8C3DADF6C815D778450C193C6637.ajp13_worker; Hm_lvt_ce55bfda158556585a8b7b246346c8ba=1498560244,1498739070,1498833193,1498917432; Hm_lpvt_ce55bfda158556585a8b7b246346c8ba=1498917597; CNZZDATA1262047894=1598545996-1495973145-%7C1498917578
       
      username=hfcai&sex=man
      ```

      

  - 服务器响应消息（响应报文）

    - 报文首部->状态行

    - 报文首部->消息报头

    - 空行

    - 报文主体->响应正文

    - ```
      HTTP/1.1 200 OK
      Date: Mon, 27 Jul 2009 12:28:53 GMT
      Server: Apache
      Last-Modified: Wed, 22 Jul 2009 19:15:56 GMT
      ETag: "34aa387-d-1568eb00"
      Accept-Ranges: bytes
      Content-Length: 51
      Vary: Accept-Encoding
      Content-Type: text/plain
      ```

  #### GET、POST、PUT、DELETE

  - 参考[HTTP中GET，POST和PUT的区别](https://blog.csdn.net/qq_36183935/article/details/80570062?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.control)
  - 参考[浅谈HTTP中Get、Post、Put与Delete的区别](https://blog.csdn.net/haif_city/article/details/78333213?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-5.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-5.control)

  - GET是从服务器上获取数据，POST是向服务器传送数据。
  - GET请求会向数据库发索取数据的请求，从而来获取信息，该请求就像数据库的select操作一样，只是用来查询一下数据，不会修改、增加数据，不会影响资源的内容，即该请求不会产生副作用。无论进行多少次操作，结果都是一样的。
  - 与GET不同的是，PUT请求是向服务器端发送数据的，从而改变信息，该请求就像数据库的update操作一样，用来修改数据的内容，但是不会增加数据的种类等，也就是说无论进行多少次PUT操作，其结果并没有不同。
  - POST请求同PUT请求类似，都是向服务器端发送数据的，但是该请求会改变数据的种类等资源，就像数据库的insert操作一样，会创建新的内容。几乎目前所有的提交操作都是用POST请求的。
  - DELETE请求顾名思义，就是用来删除某一个资源的，该请求就像数据库的delete操作。
  - GET请求会被浏览器主动cache，而POST不会，除非手动设置。
  - Get 请求中有非 ASCII 字符，会在请求之前进行转码，POST不用，因为POST在Request body中，通过 MIME，也就可以传输非 ASCII 字符。
  - GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
  - GET产生一个TCP数据包；POST产生两个TCP数据包。对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。
  - 生成方式不同：
    - GET：URL输入；超连接；Form表单中method属性为get；Form表单中method为空。
    - POST只有一种：Form表单中method为Post。
  - 数据传送方式：
    - GET传递的请求数据按照key-value的方式放在URL后面，在网址中可以直接看到，使用?分割URL和传输数据，传输的参数之间以&相连，如：login.action?name=user&password=123。所以安全性差。
    - POST方法会把请求的参数放到请求头部和空格下面的请求数据字段就是请求正文（请求体）中以&分隔各个字段，请求行不包含参数，URL中不会额外附带参数。所以安全性高。
  - 发送数据大小的限制：
    - 通常GET请求可以用于获取轻量级的数据，而POST请求的内容数据量比较庞大些。
    - GET：1~2KB。get方法提交数据的大小直接影响到了URL的长度，但HTTP协议规范中其实是没有对URL限制长度的，限制URL长度的是客户端或服务器的支持的不同所影响。
    - POST：没有要求。post方式HTTP协议规范中也没有限定，起限制作用的是服务器的处理程序的能力。
  - 提交数据的安全：
    - POST比GET方式的安全性要高。GET安全性差，POST安全性高。
    - 通过GET提交数据，用户名和密码将明文出现在URL上，如果登录页面有浏览器缓存，或者其他人查看浏览器的历史记录，那么就可以拿到用户的账号和密码了。安全性将会很差。

  #### 状态码

  - 参考[HTTP状态码](https://www.runoob.com/http/http-status-codes.html)

  - 1** 信息，服务器收到请求，需要请求者继续执行操作
    - 100（Continue）继续。客户端应继续其请求
    - 101（Switching Protocols）切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议
  - 2** 成功，操作被成功接收并处理
    - 200（ OK）请求成功。一般用于GET与POST请求
    - 201（Created）已创建。成功请求并创建了新的资源
    - 202（Accepted）已接受。已经接受请求，但未处理完成
    - 203（Non-Authoritative Information）非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本
    - 204（No Content）无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档
    - 205（Reset Content）重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域
    - 206（Partial Content）部分内容。服务器成功处理了部分GET请求
  - 3** 重定向，需要进一步的操作以完成请求
    - 301 资源（网页等）被永久转移到其他URL
  - 4** 客户端错误，请求包含语法错误或无法完成请求
    - 404 请求的资源（网页等）不存在
  - 5** 服务器错误，服务器在处理请求的过程中发生了错误
    - 500（Internal Server Error）内部服务器错误
    - 501（Not Implemented）服务器不支持请求的功能，无法完成请求
    - 502（Bad Gateway）作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应
    - 503（Service Unavailable）由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中
    - 504（ Gateway Time-out） 充当网关或代理的服务器，未及时从远端服务器获取请求
    - 505（ HTTP Version not supported）服务器不支持请求的HTTP协议的版本，无法完成处理

  #### Http1.0、Http1.1、Http2.0

  - 参考[HTTP1.0和HTTP1.1和HTTP2.0的区别](https://blog.csdn.net/ailunlee/article/details/97831912?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control)

  - 长连接
    - HTTP1.1支持长连接和请求的流水线处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启长连接keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。
    - HTTP1.0需要使用keep-alive参数来告知服务器端要建立一个长连接。
  - 节约带宽
    - HTTP1.0中存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能。
    - HTTP1.1支持只发送header信息（不带任何body信息），如果服务器认为客户端有权限请求服务器，则返回100，客户端接收到100才开始把请求body发送到服务器；如果返回401，客户端就可以不用发送请求body了节约了带宽。
  - HOST域
    - 在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname），HTTP1.0没有host域。随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。
    - HTTP1.1的请求消息和响应消息都支持host域，且请求消息中如果没有host域会报告一个错误（400 Bad Request）。
  - 缓存处理
    - 在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准。
    - HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。
  - 错误通知的管理
    - 在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
  - 多路复用
    - HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。
    - HTTP1.1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的。
  - 头部数据的压缩
    - 在HTTP1.1中，HTTP请求和响应都是由状态行、请求/响应头部、消息主体三部分组成。一般而言，消息主体都会经过gzip压缩，或者本身传输的就是压缩过后的二进制文件，但状态行和头部却没有经过任何压缩，直接以纯文本传输。随着Web功能越来越复杂，每个页面产生的请求数也越来越多，导致消耗在头部的流量越来越多，尤其是每次都要传输UserAgent、Cookie这类不会频繁变动的内容，完全是一种浪费。
    - HTTP1.1不支持header数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。
  - 服务器推送
    - 服务端推送是一种在客户端请求之前发送数据的机制。网页使用了许多资源：HTML、样式表、脚本、图片等等。在HTTP1.1中这些资源每一个都必须明确地请求。这是一个很慢的过程。浏览器从获取HTML开始，然后在它解析和评估页面的时候，增量地获取更多的资源。因为服务器必须等待浏览器做每一个请求，网络经常是空闲的和未充分使用的。
    - 为了改善延迟，HTTP2.0引入了server push，它允许服务端推送资源给浏览器，在浏览器明确地请求之前，免得客户端再次创建连接发送请求到服务器端获取。这样客户端可以直接从本地加载这些资源，不用再通过网络。

  #### 如何处理长连接

  - [Http怎么处理长连接](https://blog.csdn.net/qiuchaoxi/article/details/79957817?utm_source=blogxgwz0)
  - 在HTTP1.0和HTTP1.1协议中都有对长连接的支持。其中HTTP1.0需要在request中增加Connection： keep-alive header才能够支持，而HTTP1.1默认支持。
  - http1.0请求与服务端的交互过程:
    - 客户端发出带有包含一个header：”Connection： keep-alive“的请求
    - 服务端接收到这个请求后,根据http1.0和”Connection： keep-alive“判断出这是一个长连接,就会在response的header中也增加”Connection： keep-alive“，同时不会关闭已建立的tcp连接.
    - 客户端收到服务端的response后,发现其中包含”Connection： keep-alive“，就认为是一个长连接，不关闭这个连接。并用该连接再发送request.转到第一步
  - http1.1请求与服务端的交互过程：
    - 客户端发出http1.1的请求
    - 服务端收到http1.1后就认为这是一个长连接,会在返回的response设置Connection： keep-alive,同时不会关闭已建立的连接.
    - 客户端收到服务端的response后,发现其中包含”Connection： keep-alive“，就认为是一个长连接，不关闭这个连接。并用该连接再发送request.转到第一步
  - 基于http协议的长连接减少了请求,减少了建立连接的时间,但是每次交互都是由客户端发起的,客户端发送消息,服务端才能返回客户端消息。

  ### HTTP与TCP区别

  - TCP是传输层，而http是应用层。TCP就是单纯建立连接，不涉及任何我们需要请求的实际数据，简单的传输。http是用来收发数据，即实际应用上来的。

  ### HTTPS

  - 中间人攻击
    - 服务器向客户端发送公钥。
    - 攻击者截获公钥，保留在自己手上。
    - 然后攻击者自己生成一个【伪造的】公钥，发给客户端。
    - 客户端收到伪造的公钥后，生成加密hash值发给服务器。
    - 攻击者获得加密hash值，用自己的私钥解密获得真秘钥。
    - 同时生成假的加密hash值，发给服务器。
    - 服务器用私钥解密获得假秘钥。
    - 服务器用加秘钥加密传输信息

  ### HTTPS与HTTP区别

  - [HTTP 和 HTTPS 的区别](https://blog.csdn.net/qq_38289815/article/details/80969419)
  - HTTPS协议需要到CA申请证书，一般免费证书很少，需要交费。
  - HTTP协议运行在TCP之上，所有传输的内容都是明文，HTTPS运行在SSL/TLS之上，SSL/TLS运行在TCP之上，所有传输的内容都经过加密的。
  - HTTP和HTTPS使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
  - HTTPS可以有效的防止运营商劫持，解决了防劫持的一个大问题。

  ### IOCP

  - 参考[IOCP模型与网络编程](https://blog.csdn.net/neicole/article/details/7549497)
  - 参考[完成端口(CompletionPort)详解 - 手把手教你玩转网络编程系列之三](https://blog.csdn.net/PiggyXP/article/details/6922277)

  #### 介绍

  - IOCP（I/O Comlpetion Port），常称I/O完成端口
  - IOCP模型属于一种通讯模型，适用于(能控制并发执行的)高负载服务器的一个技术。
  - 通俗一点说，就是用于高效处理很多很多的客户端进行数据交换的一个模型。或者可以说，就是能异步I/O操作的模型。会利用Windows内核来进行I/O的调度。

  #### 优点

  - 帮助维持重复使用的内存池。(与重叠I/O技术有关)
  - 去除删除线程创建/终结负担。
  - 利于管理，分配线程，控制并发，最小化的线程上下文切换。
  - 优化线程调度，提高CPU和内存缓冲的命中率。

  ### Epoll

#### 水平模式（LT）

- 默认模式
- 只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作。

#### 边缘模式（ET）

- 当这个fd数据可读的时候，只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读光，也就是说一直读到read的返回值小于请求值，或者 遇到EAGAIN错误。

#### 为什么有ET模式？

- 采用LT时，系统中一旦有大量你不需要读写的就绪文件描述符，它们每次调用epoll_wait都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率。
- 而采用EPOLL ET这种边沿触发模式的话，当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你！！！这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符

#### ET模式为什么要把socket设为非阻塞？

- [浅谈 epoll 中 ET 和 LT 与 阻塞/非阻塞 IO](https://www.cnblogs.com/lawliet12/p/13508057.html)
- [使用epoll时需要将socket设为非阻塞吗？ - 文武双缺的回答 - 知乎 ](https://www.zhihu.com/question/23614342/answer/184513538)
- ET 模式是一种边沿触发模型，在它检测到有 I/O 事件时，通过 epoll_wait 调用会得到有事件通知的文件描述符，每于每一个被通知的文件描述符，如可读，则必须将该文件描述符一直读到空，让 errno 返回 EAGAIN 为止，否则下次的 epoll_wait 不会返回余下的数据，会丢掉事件。而如果你的文件描述符如果不是非阻塞的，那这个一直读或一直写势必会在最后一次阻塞。
- 非阻塞IO：当你去读写一个非阻塞的文件描述符时，不管可不可以读写，它都会立即返回，返回成功说明读写操作完成了，返回失败会设置相应errno状态码，根据这个errno可以进一步执行其他处理。它不会像阻塞IO那样，卡在那里不动。

### Select、Poll和Epoll区别

- [select、poll、epoll之间的区别(搜狗面试)](https://www.cnblogs.com/aspirant/p/9166944.html)

- Select：

  - 有I/O事件发生，无差别轮询所有流，找出能读或写的流。
  - 时间复杂度O(n)
  - 通过设置或者检查存放fd标志位的数据结构来进行下一步处理。缺点是：
    - 单个进程可监视的fd数量被限制，即能监听端口的大小有限。一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048。
    - 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。
    - 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大

- Poll：

  - 相对于Select无最大连接数的限制，原因是它是基于链表存储的。
  - 时间复杂度O(n)
  - 缺点：
    - 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。
    - poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。

- Epoll：

  - epoll会把哪个流发生了怎么样的I/O事件通知我们。

  - 时间复杂度O(1)
  - 优点：
    - 没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）
    - 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数
    - 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。

### 粘包

#### 粘包出现原因

- 在流传输中出现，UDP不会出现粘包，因为它有消息边界(参考Windows 网络编程)
- 发送端需要等缓冲区满才发送出去，造成粘包
- 接收方不及时接收缓冲区的包，造成多个包接收

#### 粘包解决方法

- 为了避免粘包现象，可采取以下几种措施。一是对于发送方引起的粘包现象，用户可通过编程设置来避免，TCP提供了强制数据立即传送的操作指令push，TCP软件收到该操作指令后，就立即将本段数据发送出去，而不必等待发送缓冲区满；二是对于接收方引起的粘包，则可通过优化程序设计、精简接收进程工作量、提高接收进程优先级等措施，使其及时接收数据，从而尽量避免出现粘包现象；三是由接收方控制，将一包数据按结构字段，人为控制分多次接收，然后合并，通过这种手段来避免粘包。
- 以上提到的三种措施，都有其不足之处。第一种编程设置方法虽然可以避免发送方引起的粘包，但它关闭了优化算法，降低了网络发送效率，影响应用程序的性能，一般不建议使用。第二种方法只能减少出现粘包的可能性，但并不能完全避免粘包，当发送频率较高时，或由于网络突发可能使某个时间段数据包到达接收方较快，接收方还是有可能来不及接收，从而导致粘包。第三种方法虽然避免了粘包，但应用程序的效率较低，对实时应用的场合不适合。

### 序列化

- [主流序列化协议优缺点对比和开发必备网站](http://www.mamicode.com/info-detail-2443824.html)

#### json

- 优点：
  - 简单易用、开发成本低
  - 跨语言
  - 轻量级数据交换
  - 非冗长性（对比xml标签简单括号闭环）
- 缺点：
  - 体积大，影响高并发
  - 无版本检查，自己做兼容
  - 片段的创建和验证过程比一般的xml复杂
  - 缺乏命名空间导致信息混合
- 总结：
  - 最简单最通用的应用协议，使用广泛，开发效率高，性能相对较低，维护成本较高。

#### protobuf

- Protobuf是一种以有效并可扩展的格式编码结构化数据的方式。

- 优点：
  - 跨语言，可自定义数据结构。
  - 字段被编号，新添加的字段不影响老结构。解决了向后兼容问题。
  - 自动化生成代码，简单易用。
  - 二进制消息，效率高，性能高。
  - Netty等框架集成了该协议，提供了编×××提高开发效率。
- 缺点：
  - 二进制格式，可读性差（抓包dump后的数据很难看懂）
  - 对象冗余，字段很多，生成的类较大，占用空间。
  - 默认不具备动态特性（可以通过动态定义生成消息类型或者动态编译支持）
- 总结：
  - 简单快速上手，高效兼容性强，维护成本较高。

#### msgpack

- 优点：
  - 跨语言，多语言支持(超多)
  - It’s like JSON.but fast and small.序列化反序列化效率高（比json快一倍），文件体积小，比json小一倍。
  - 兼容json数据格式
- 缺点：
  - 缺乏复杂模型支持。msgpack对复杂的数据类型（List、Map）支持的不够，序列化没有问题，但是反序列化回来就很麻烦，尤其是对于java开发人员。
  - 维护成本较高。msgpack通过value的顺序来定位属性的，需要在不同的语言中都要维护同样的模型以及模型中属性的顺序。
  - 不支持模型嵌套。msgpack无法支持在模型中包含和嵌套其他自定义的模型（如weibo模型中包含comment的列表）。
- 总结：
  - 高性能但扩展性较差维护成本较高。

### 加密

- [对称与非对称加密算法](https://blog.csdn.net/liudongdong19/article/details/82217431)

#### 对称加密

- 加密和解密使用相同密钥的加密算法。
- 常用的算法：
  -  DES（Data Encryption Standard）：数据加密标准，速度较快，适用于加密大量数据的场合。
  -  3DES（Triple DES）：是基于DES，对一块数据用三个不同的密钥进行三次加密，强度更高。
  -  AES（Advanced Encryption Standard）：高级加密标准，是下一代的加密算法标准，速度快，安全级别高；

#### 非对称加密

- 指加密和解密使用不同密钥的加密算法，也称为公私钥加密。假设两个用户要加密交换数据，双方交换公钥，使用时一方用对方的公钥加密，另一方即可用自己的私钥解密。
- 常用的算法：
  -  RSA：由 RSA 公司发明，是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的；
  -  DSA（Digital Signature Algorithm）：数字签名算法，是一种标准的 DSS（数字签名标准）；
  -  ECC（Elliptic Curves Cryptography）：椭圆曲线密码编码学。

#### 加密算法选择

- 由于非对称加密算法的运行速度比对称加密算法的速度慢很多，当我们需要加密大量的数据时，建议采用对称加密算法，提高加解密速度。
- 对称加密算法不能实现签名，因此签名只能非对称算法。
- 由于对称加密算法的密钥管理是一个复杂的过程，密钥的管理直接决定着他的安全性，因此当数据量很小时，我们可以考虑采用非对称加密算法。
- 在实际的操作过程中，我们通常采用的方式是：采用非对称加密算法管理对称算法的密钥，然后用对称加密算法加密数据，这样我们就集成了两类加密算法的优点，既实现了加密速度快的优点，又实现了安全方便管理密钥的优点。

### 浏览器输入URL的过程，用到了哪些协议？

- [在浏览器中输入URL后，执行的全部过程。会用到哪些协议？（一次完整的HTTP请求过程）](https://blog.csdn.net/hellodake/article/details/81974421)

- 首先进行域名解析，域名解析具体过程讲一下：

  - 浏览器搜索自己的DNS缓存，缓存中维护一张域名与IP地址的对应表；
  - 若没有，则搜索操作系统的DNS缓存；
  - 若没有，则操作系统将域名发送至本地域名服务器（递归查询方式），本地域名服务器查询自己的DNS缓存，查找成功则返回结果，否则，通过以下方式迭代查找：
    - 本地域名服务器向根域名服务器发起请求，根域名服务器返回com域的顶级域名服务器的地址；
    - 本地域名服务器向com域的顶级域名服务器发起请求，返回权限域名服务器地址；
    - 本地域名服务器向权限域名服务器发起请求，得到IP地址；

  - 本地域名服务器将得到的IP地址返回给操作系统，同时自己将IP地址缓存起来；
  - 操作系统将IP地址返回给浏览器，同时自己也将IP地址缓存起来；
  - 至此，浏览器已经得到了域名对应的IP地址。

- 浏览器发起HTTP请求；

- 接下来到了传输层，选择传输协议，TCP或者UDP，TCP是可靠的传输控制协议，对HTTP请求进行封装，加入了端口号等信息；

- 然后到了网络层，通过IP协议将IP地址封装为IP数据报；然后此时会用到ARP协议，主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回消息，以此确定目标的物理地址，找到目的MAC地址；

- 接下来到了数据链路层，把网络层交下来的IP数据报添加首部和尾部，封装为MAC帧，现在根据目的mac开始建立TCP连接，三次握手，接收端在收到物理层上交的比特流后，根据首尾的标记，识别帧的开始和结束，将中间的数据部分上交给网络层，然后层层向上传递到应用层；

- 服务器响应请求并请求客户端要的资源，传回给客户端；

- 断开TCP连接，浏览器对页面进行渲染呈现给客户端。

### protobuf熟不熟，压缩原理，它怎么实现兼容性的。

- 

### IO

- IO执行的两个阶段： 等待数据准备， 将数据从内核拷贝到进程中 
  - 进程请求数据（调用recvfrom）。  内核准备数据。如果网络未收到一个完整的包或者没有数据到达，则进程阻塞；如果内核数据准备好了，内核将数据从内核拷贝到用户内存，然后返回结果，用户进程不再阻塞，重新运行。
  - IO执行的两个阶段，进程都被阻塞。非阻塞IO：  进程请求数据（调用recvfrom）。 内核准备数据。如果数据未准备好，返回一个error，进程不阻塞。数据如果准备好，进程需要再次调用recvfrom将数据拷贝到用户内存，然后返回。 用户进程每次询问内核，内核都会返回结果；所有用户进程需要不断的询问内核。阻塞一次，当数据完成之后，调用recvfrom，进程阻塞。 
  - IO复用（也称：事件驱动IO，例：select、epoll等等）：进程请求数据（调用select），整个进程阻塞，同时，内核监视所有select负责的socket，当任何一个socket的数据准备好，select返回。用户调用read操作，将数据从内核拷贝到用户内存。  两次系统调用（select、recvfrom）。 
    - 整个过程只在调用select、poll、epoll这些调用的时候才会阻塞，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是事件驱动，所谓的reactor模式。
  - 信号驱动模型： 首先开启套接字的信号驱动式I/O功能，并通过sigaction系统调用来安装一个信号处理函数，进程不会被阻塞。当数据报准备好读取时，内核为该进程产生一个SIGIO信号，此时我们可以在信号处理函数中调用recvfrom读取数据报，并通知数据已经准备好，等待处理。 
    - 缺点： 信号是一个被过度设计的机制。 信号I/O在大量IO操作时可能会因为信号队列溢出导致无法通知。 
      异步IO： 进程请求数据（调用read）。内核立刻返回，进程不阻塞，内核等待数据准备好之后，将数据拷贝到用户内存，完成之后，给用户进程发一个signal，通知read完成。 
    - 不阻塞，链接：[IO - 同步，异步，阻塞，非阻塞 （亡羊补牢篇）](https://blog.csdn.net/historyasamirror/article/details/5778378)

### TCP建立连接是什么？真的有连接吗？

- 其实就是一个对端发送数据的序列号而已。

### 问题

- enet、kcp

- 封包：封包就是给一段数据加上包头，这样一来数据包就分为包头和包体两部分内容了(以后讲过滤非法包时封包会加入"包尾"内容)。包头其实上是个大小固定的结构体，其中有个结构体成员变量表示包体的长度，这是个很重要的变量，其他的结构体成员可根据需要自己定义。根据包头长度固定以及包头中含有包体长度的变量就能正确的拆分出一个完整的数据包。
- 解包：[socket 封包和解包](https://blog.csdn.net/u012861978/article/details/50962779)
- 在不同局域网中，如何访问web(localhost)，服务器如何接受、连接？竞争资源及分配？
- socket模型。C/S模式下使用socket通信，几个关键函数。
- OSI与TCP/IP各层的结构与功能，都有哪些协议。 OSI七层模型
- Cookie与Session的原理及区别。 
- IP地址分类。 
- 路由器与交换机区别。
- 阻塞IO、非阻塞IO、IO复用、异步IO区别 
- Windows IOCP模型与Linux EPOLL模块之比较：[Windows IOCP模型与Linux EPOLL模块之比较](https://blog.csdn.net/educast/article/details/15500349 )
  - epoll：事件类、套接字类、事件处理epoll类、事件状态类 
  - iocp：开始发送、停止发送、开始接收、停止接收、获取状态、获取套接字、获取发送数据、获取接收数据、关闭、完成发送、完成接收、再次发送、  
- [socket中的函数遇见EINTR的处理](